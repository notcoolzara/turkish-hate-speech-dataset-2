{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmnxqbIMiLwi",
        "outputId": "238e719f-6a08-4103-a4c5-ef0be072f473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zemberek-python\n",
            "  Downloading zemberek_python-0.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.8 (from zemberek-python)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from zemberek-python) (1.26.4)\n",
            "Downloading zemberek_python-0.2.3-py3-none-any.whl (95.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141214 sha256=4892517a57593b8bf31447f836cf6248140da635821e0206d0e7dd8585f8bdd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, zemberek-python\n",
            "Successfully installed antlr4-python3-runtime-4.8 zemberek-python-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install zemberek-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX_oi9T53BJg",
        "outputId": "b75f16f0-b5d5-4562-8346-f3f325a6307a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from google.colab import drive\n",
        "from zemberek import TurkishMorphology, TurkishSpellChecker\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeU4NWH73JDD"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "dataset_path = '/content/drive/My Drive/DATASET/final_hate_speech.xlsx'\n",
        "word2vec_path = '/content/drive/My Drive/DATASET/word2vec_tr.model'\n",
        "fine_tuned_path = '/content/drive/My Drive/DATASET/word2vec_tr_finetuned.model'\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_excel(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTcu10Nb35dX",
        "outputId": "387c6e7c-ee9f-4e1b-f823-9e50bee51f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:zemberek.morphology.turkish_morphology:TurkishMorphology instance initialized in 31.25755548477173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 16:04:35,878 - zemberek.morphology.turkish_morphology - INFO\n",
            "Msg: TurkishMorphology instance initialized in 31.25755548477173\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize Zemberek for spell checking\n",
        "morphology = TurkishMorphology.create_with_defaults()\n",
        "spell_checker = TurkishSpellChecker(morphology)\n",
        "\n",
        "cache = {}\n",
        "\n",
        "def clean_turkish_text_with_cache(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
        "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])  # Keep alphanumeric and spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    corrected_words = []\n",
        "    for word in text.split():\n",
        "        if word in cache:\n",
        "            corrected_words.append(cache[word])\n",
        "        else:\n",
        "            suggestions = spell_checker.suggest_for_word(word)\n",
        "            correction = suggestions[0] if suggestions else word\n",
        "            cache[word] = correction\n",
        "            corrected_words.append(correction)\n",
        "    return ' '.join(corrected_words) if corrected_words else \"EMPTY\"\n",
        "\n",
        "# Apply preprocessing with caching\n",
        "data['tweet_cleaned'] = data['tweet'].apply(clean_turkish_text_with_cache)\n",
        "\n",
        "# Tokenize cleaned tweets\n",
        "sentences = [tweet.split() for tweet in data['tweet_cleaned'] if tweet != \"EMPTY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmD4QJ1j7sxq",
        "outputId": "ebab29d4-2924-49d4-b4aa-b443215a8587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.keyedvectors:loading projection weights from /content/drive/My Drive/DATASET/word2vec_tr.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:04,087 - gensim.models.keyedvectors - INFO\n",
            "Msg: loading projection weights from /content/drive/My Drive/DATASET/word2vec_tr.model\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:KeyedVectors lifecycle event {'msg': 'loaded (412457, 400) matrix of type float32 from /content/drive/My Drive/DATASET/word2vec_tr.model', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-01-03T17:19:23.219908', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,220 - gensim.utils - INFO\n",
            "Msg: KeyedVectors lifecycle event {'msg': 'loaded (412457, 400) matrix of type float32 from /content/drive/My Drive/DATASET/word2vec_tr.model', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-01-03T17:19:23.219908', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=400, alpha=0.025>', 'datetime': '2025-01-03T17:19:23.241849', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'created'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,241 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=400, alpha=0.025>', 'datetime': '2025-01-03T17:19:23.241849', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'created'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:collecting all words and their counts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,246 - gensim.models.word2vec - INFO\n",
            "Msg: collecting all words and their counts\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,253 - gensim.models.word2vec - INFO\n",
            "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 212849 words, keeping 39996 word types\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,403 - gensim.models.word2vec - INFO\n",
            "Msg: PROGRESS: at sentence #10000, processed 212849 words, keeping 39996 word types\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:collected 40614 word types from a corpus of 218268 raw words and 10224 sentences\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,413 - gensim.models.word2vec - INFO\n",
            "Msg: collected 40614 word types from a corpus of 218268 raw words and 10224 sentences\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,422 - gensim.models.word2vec - INFO\n",
            "Msg: Creating a fresh vocabulary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 40614 unique words (100.00% of original 40614, drops 0)', 'datetime': '2025-01-03T17:19:23.690674', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,690 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 40614 unique words (100.00% of original 40614, drops 0)', 'datetime': '2025-01-03T17:19:23.690674', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 218268 word corpus (100.00% of original 218268, drops 0)', 'datetime': '2025-01-03T17:19:23.697284', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:23,697 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 218268 word corpus (100.00% of original 218268, drops 0)', 'datetime': '2025-01-03T17:19:23.697284', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 40614 items\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:24,022 - gensim.models.word2vec - INFO\n",
            "Msg: deleting the raw counts dictionary of 40614 items\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:sample=0.001 downsamples 35 most-common words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:24,039 - gensim.models.word2vec - INFO\n",
            "Msg: sample=0.001 downsamples 35 most-common words\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 198187.92663335195 word corpus (90.8%% of prior 218268)', 'datetime': '2025-01-03T17:19:24.043115', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:24,043 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 198187.92663335195 word corpus (90.8%% of prior 218268)', 'datetime': '2025-01-03T17:19:24.043115', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:estimated required memory for 40614 words and 400 dimensions: 150271800 bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:25,101 - gensim.models.word2vec - INFO\n",
            "Msg: estimated required memory for 40614 words and 400 dimensions: 150271800 bytes\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:resetting layer weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:25,106 - gensim.models.word2vec - INFO\n",
            "Msg: resetting layer weights\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-01-03T17:19:25.517372', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:25,517 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-01-03T17:19:25.517372', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:collecting all words and their counts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:25,559 - gensim.models.word2vec - INFO\n",
            "Msg: collecting all words and their counts\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:25,564 - gensim.models.word2vec - INFO\n",
            "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:collected 412457 word types from a corpus of 412457 raw words and 1 sentences\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:26,074 - gensim.models.word2vec - INFO\n",
            "Msg: collected 412457 word types from a corpus of 412457 raw words and 1 sentences\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:Updating model with new vocabulary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:26,078 - gensim.models.word2vec - INFO\n",
            "Msg: Updating model with new vocabulary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'added 388042 new unique words (94.08% of original 412457) and increased the count of 24415 pre-existing words (5.92% of original 412457)', 'datetime': '2025-01-03T17:19:31.248236', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:31,248 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'msg': 'added 388042 new unique words (94.08% of original 412457) and increased the count of 24415 pre-existing words (5.92% of original 412457)', 'datetime': '2025-01-03T17:19:31.248236', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 412457 items\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:33,776 - gensim.models.word2vec - INFO\n",
            "Msg: deleting the raw counts dictionary of 412457 items\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:sample=0.001 downsamples 0 most-common words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:33,788 - gensim.models.word2vec - INFO\n",
            "Msg: sample=0.001 downsamples 0 most-common words\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 412457 word corpus (100.0%% of prior 412457)', 'datetime': '2025-01-03T17:19:33.792662', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:33,792 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 412457 word corpus (100.0%% of prior 412457)', 'datetime': '2025-01-03T17:19:33.792662', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:estimated required memory for 412457 words and 400 dimensions: 1526090900 bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:37,233 - gensim.models.word2vec - INFO\n",
            "Msg: estimated required memory for 412457 words and 400 dimensions: 1526090900 bytes\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:updating layer weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:37,237 - gensim.models.word2vec - INFO\n",
            "Msg: updating layer weights\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2025-01-03T17:19:39.137634', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:39,137 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2025-01-03T17:19:39.137634', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 3 workers on 428656 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-01-03T17:19:40.239571', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:40,239 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'msg': 'training model with 3 workers on 428656 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-01-03T17:19:40.239571', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'train'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 0: training on 218268 raw words (216608 effective words) took 0.9s, 252512 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:41,109 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 0: training on 218268 raw words (216608 effective words) took 0.9s, 252512 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 100.00% examples, 213343 words/s, in_qsize 0, out_qsize 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:42,135 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 1 - PROGRESS: at 100.00% examples, 213343 words/s, in_qsize 0, out_qsize 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 1: training on 218268 raw words (216637 effective words) took 1.0s, 212201 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:42,140 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 1: training on 218268 raw words (216637 effective words) took 1.0s, 212201 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 68.17% examples, 144509 words/s, in_qsize 5, out_qsize 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:43,199 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 2 - PROGRESS: at 68.17% examples, 144509 words/s, in_qsize 5, out_qsize 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 2: training on 218268 raw words (216635 effective words) took 1.4s, 152310 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:43,593 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 2: training on 218268 raw words (216635 effective words) took 1.4s, 152310 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 68.17% examples, 144447 words/s, in_qsize 6, out_qsize 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:44,641 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 3 - PROGRESS: at 68.17% examples, 144447 words/s, in_qsize 6, out_qsize 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 3: training on 218268 raw words (216615 effective words) took 1.4s, 154214 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:45,018 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 3: training on 218268 raw words (216615 effective words) took 1.4s, 154214 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 73.03% examples, 140294 words/s, in_qsize 5, out_qsize 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:46,169 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 4 - PROGRESS: at 73.03% examples, 140294 words/s, in_qsize 5, out_qsize 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 4: training on 218268 raw words (216659 effective words) took 1.4s, 154074 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:46,446 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 4: training on 218268 raw words (216659 effective words) took 1.4s, 154074 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 57.53% examples, 127259 words/s, in_qsize 6, out_qsize 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:47,471 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 5 - PROGRESS: at 57.53% examples, 127259 words/s, in_qsize 6, out_qsize 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 5: training on 218268 raw words (216633 effective words) took 1.4s, 151334 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:47,891 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 5: training on 218268 raw words (216633 effective words) took 1.4s, 151334 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 6: training on 218268 raw words (216608 effective words) took 0.8s, 257719 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:48,744 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 6: training on 218268 raw words (216608 effective words) took 0.8s, 257719 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 7: training on 218268 raw words (216610 effective words) took 0.9s, 248276 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:49,628 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 7: training on 218268 raw words (216610 effective words) took 0.9s, 248276 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 8: training on 218268 raw words (216618 effective words) took 0.8s, 259597 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:50,473 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 8: training on 218268 raw words (216618 effective words) took 0.8s, 259597 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.models.word2vec:EPOCH 9: training on 218268 raw words (216644 effective words) took 0.8s, 258809 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:51,320 - gensim.models.word2vec - INFO\n",
            "Msg: EPOCH 9: training on 218268 raw words (216644 effective words) took 0.8s, 258809 effective words/s\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 2182680 raw words (2166267 effective words) took 11.1s, 195496 effective words/s', 'datetime': '2025-01-03T17:19:51.324872', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:51,324 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'msg': 'training on 2182680 raw words (2166267 effective words) took 11.1s, 195496 effective words/s', 'datetime': '2025-01-03T17:19:51.324872', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'train'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:Word2Vec lifecycle event {'fname_or_handle': '/content/drive/My Drive/DATASET/word2vec_tr_finetuned.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-01-03T17:19:51.328354', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'saving'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:51,328 - gensim.utils - INFO\n",
            "Msg: Word2Vec lifecycle event {'fname_or_handle': '/content/drive/My Drive/DATASET/word2vec_tr_finetuned.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-01-03T17:19:51.328354', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35', 'event': 'saving'}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:storing np array 'vectors' to /content/drive/My Drive/DATASET/word2vec_tr_finetuned.model.wv.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:19:51,331 - gensim.utils - INFO\n",
            "Msg: storing np array 'vectors' to /content/drive/My Drive/DATASET/word2vec_tr_finetuned.model.wv.vectors.npy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:storing np array 'syn1neg' to /content/drive/My Drive/DATASET/word2vec_tr_finetuned.model.syn1neg.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:20:10,906 - gensim.utils - INFO\n",
            "Msg: storing np array 'syn1neg' to /content/drive/My Drive/DATASET/word2vec_tr_finetuned.model.syn1neg.npy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:not storing attribute cum_table\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:20:35,828 - gensim.utils - INFO\n",
            "Msg: not storing attribute cum_table\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.utils:saved /content/drive/My Drive/DATASET/word2vec_tr_finetuned.model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-03 17:20:36,861 - gensim.utils - INFO\n",
            "Msg: saved /content/drive/My Drive/DATASET/word2vec_tr_finetuned.model\n",
            "\n"
          ]
        }
      ],
      "source": [
        " # Load pre-trained Word2Vec model\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
        "\n",
        "# Fine-tune Word2Vec\n",
        "new_model = Word2Vec(vector_size=word2vec_model.vector_size, min_count=1)\n",
        "new_model.build_vocab(sentences)\n",
        "new_model.build_vocab([list(word2vec_model.key_to_index.keys())], update=True)\n",
        "new_model.wv.vectors = np.copy(word2vec_model.vectors)\n",
        "new_model.train(sentences, total_examples=len(sentences), epochs=10)\n",
        "new_model.save(fine_tuned_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "3MVmnBhagRkB",
        "outputId": "e9212d1f-a75f-4305-b2ff-51910929d672"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID                                              tweet     etiket  \\\n",
              "0   1  ya orospu cocuklari hepiniz niye ayni anda yaz...     nefret   \n",
              "1   2  Ciddiye alan tüm dünyanın beynini sileyim.. \\n...  saldırgan   \n",
              "2   3  Kayıtlı İstihdama geçiş programına göre (?)\\nŞ...    hiçbiri   \n",
              "3   4  Hastaneye git Suriyeli. PTT ye git Suriyeli. P...     nefret   \n",
              "4   5               Cölesi bitmiş suriyeli gibiyim bugün    hiçbiri   \n",
              "\n",
              "  alt etiket favorited  retweeted  is retweet user - followers  \\\n",
              "0      etnik        12          1           0             2860   \n",
              "1        NaN         3          0           0              314   \n",
              "2        NaN        26          1           0            12548   \n",
              "3      etnik         0          0           0                9   \n",
              "4        NaN        48          2           0              488   \n",
              "\n",
              "                  time   Keyword  \\\n",
              "0  2019-09-05 11:33:56  suriyeli   \n",
              "1  2019-09-05 11:32:09  suriyeli   \n",
              "2  2019-09-05 11:29:34  suriyeli   \n",
              "3  2019-09-05 11:26:50  suriyeli   \n",
              "4  2019-09-05 11:26:19  suriyeli   \n",
              "\n",
              "                                       tweet_cleaned  \n",
              "0  da orospum cocuklari hepimiz diye aynı anda ya...  \n",
              "1  ciddiye olan tüm dünyanın beynin bileyim iki g...  \n",
              "2  kayıtlı istihdam geniş programında göre şimdil...  \n",
              "3  hastaneye ait Suriye'yi ptt de ait Suriye'yi p...  \n",
              "4              kölesi gitmiş Suriye'yi gibiyim bugün  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d63267c8-6b3b-48dd-865e-de57f7d65528\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>tweet</th>\n",
              "      <th>etiket</th>\n",
              "      <th>alt etiket</th>\n",
              "      <th>favorited</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>is retweet</th>\n",
              "      <th>user - followers</th>\n",
              "      <th>time</th>\n",
              "      <th>Keyword</th>\n",
              "      <th>tweet_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ya orospu cocuklari hepiniz niye ayni anda yaz...</td>\n",
              "      <td>nefret</td>\n",
              "      <td>etnik</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2860</td>\n",
              "      <td>2019-09-05 11:33:56</td>\n",
              "      <td>suriyeli</td>\n",
              "      <td>da orospum cocuklari hepimiz diye aynı anda ya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Ciddiye alan tüm dünyanın beynini sileyim.. \\n...</td>\n",
              "      <td>saldırgan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>314</td>\n",
              "      <td>2019-09-05 11:32:09</td>\n",
              "      <td>suriyeli</td>\n",
              "      <td>ciddiye olan tüm dünyanın beynin bileyim iki g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Kayıtlı İstihdama geçiş programına göre (?)\\nŞ...</td>\n",
              "      <td>hiçbiri</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12548</td>\n",
              "      <td>2019-09-05 11:29:34</td>\n",
              "      <td>suriyeli</td>\n",
              "      <td>kayıtlı istihdam geniş programında göre şimdil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Hastaneye git Suriyeli. PTT ye git Suriyeli. P...</td>\n",
              "      <td>nefret</td>\n",
              "      <td>etnik</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2019-09-05 11:26:50</td>\n",
              "      <td>suriyeli</td>\n",
              "      <td>hastaneye ait Suriye'yi ptt de ait Suriye'yi p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Cölesi bitmiş suriyeli gibiyim bugün</td>\n",
              "      <td>hiçbiri</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>488</td>\n",
              "      <td>2019-09-05 11:26:19</td>\n",
              "      <td>suriyeli</td>\n",
              "      <td>kölesi gitmiş Suriye'yi gibiyim bugün</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d63267c8-6b3b-48dd-865e-de57f7d65528')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d63267c8-6b3b-48dd-865e-de57f7d65528 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d63267c8-6b3b-48dd-865e-de57f7d65528');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b5a0d6d-a990-4ea9-accd-8490a329c2b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b5a0d6d-a990-4ea9-accd-8490a329c2b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b5a0d6d-a990-4ea9-accd-8490a329c2b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10224,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2951,\n        \"min\": 1,\n        \"max\": 10224,\n        \"num_unique_values\": 10224,\n        \"samples\": [\n          5380,\n          10054,\n          6876\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10166,\n        \"samples\": [\n          \"E biraz yunan m\\u00fczi\\u011fi  https://t.co/2hgMLoe9M7\",\n          \"Ye\\u011fenim bir \\u00e7ok kelimenin ingilizcesini biliyor t\\u00fcrk\\u00e7e anlam\\u0131yor. \\\"O\\u011flum sen ingiliz kraliyet ailesinden mi geliyorsun?\\\" dedim \\\"evet teyse sen de gel\\\" diyo \\ud83d\\ude04\",\n          \"1719\\u2019da yaz\\u0131lan, olaylar\\u0131n 18.yy ba\\u015f\\u0131nda \\u0130stanbul\\u2019da ge\\u00e7ti\\u011fi ve \\u00e7a\\u011fda\\u015f Yunan edebiyat\\u0131n\\u0131n roman t\\u00fcr\\u00fcndeki ilk denemesi olan bu eseri hemen okumaya ba\\u015fl\\u0131yorum. Pek yak\\u0131nda eser hakk\\u0131nda @acikradyo @gunceledebiyatt program\\u0131nda @fotibenlisoy ile kitap hakk\\u0131nda konu\\u015faca\\u011f\\u0131z. https://t.co/SFyuOwNqnA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"etiket\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"nefret\",\n          \"sald\\u0131rgan\",\n          \"hi\\u00e7biri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alt etiket\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"dini,cinsiyet\\u00e7i,siyasi\",\n          \"etnik,dini,cinsiyet\\u00e7i\",\n          \"etnik\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorited\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00\",\n        \"max\": \"2021-01-29 17:58:00\",\n        \"num_unique_values\": 348,\n        \"samples\": [\n          1188,\n          110,\n          443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweeted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 0,\n        \"max\": 2823,\n        \"num_unique_values\": 161,\n        \"samples\": [\n          145,\n          117,\n          404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is retweet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user - followers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4114,\n        \"samples\": [\n          16332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00.000043717\",\n        \"max\": \"2021-03-26 19:13:50\",\n        \"num_unique_values\": 10092,\n        \"samples\": [\n          \"2019-09-02 10:28:34\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"suriyeli\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10145,\n        \"samples\": [\n          \"g\\u00fcney k\\u0131br\\u0131s rus kesiminde camiler y\\u00f6nelik sald\\u0131r\\u0131lar\\u0131 bir yenisi daha ekledi limasol kentinde caminin duvar\\u0131n hi\\u00e7 semboller \\u00e7izildi de t\\u00fcrker \\u00f6l\\u00fcme tehdit edildiavrupa hristiyan ter\\u00f6ristleri destekliyor camiye hi\\u00e7 \\u00e7izim t\\u00fcrlere \\u00f6l\\u00fcm yaz\\u0131lar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGXQisEQ3-d9"
      },
      "outputs": [],
      "source": [
        "def text_to_word2vec(text, model, vector_size=300):\n",
        "    if not text or text.strip() == \"EMPTY\":\n",
        "        return np.zeros(vector_size, dtype=np.float32)\n",
        "    words = text.split()\n",
        "    embeddings = [model[word] for word in words if word in model.key_to_index]\n",
        "    if not embeddings:\n",
        "        return np.zeros(vector_size, dtype=np.float32)\n",
        "    return np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKNADF8iow9-"
      },
      "outputs": [],
      "source": [
        "X = np.array([text_to_word2vec(tweet, new_model.wv, vector_size=new_model.vector_size)\n",
        "             for tweet in data['tweet_cleaned']])\n",
        "y = data['etiket'].values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btLUE-dD4B6t"
      },
      "outputs": [],
      "source": [
        "# Define resampling methods\n",
        "resampling_methods = {\n",
        "    \"Original\": None,\n",
        "    \"Oversampling\": RandomOverSampler(random_state=42),\n",
        "    \"Undersampling\": RandomUnderSampler(random_state=42),\n",
        "    \"Combined\": SMOTEENN(random_state=42),\n",
        "}\n",
        "\n",
        "# Define ML models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42, tree_method='hist', use_label_encoder=False),\n",
        "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJVsR2rf4Ek4"
      },
      "outputs": [],
      "source": [
        "# ANN Model\n",
        "def build_ann(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(len(label_encoder.classes_), activation='softmax'),\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train and evaluate models\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtO5Unpp4feB",
        "outputId": "2b0be559-2f3c-4824-b40d-410356961e06"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:21:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051025 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 102000\n",
            "[LightGBM] [Info] Number of data points in the train set: 8179, number of used features: 400\n",
            "[LightGBM] [Info] Start training from score -0.277827\n",
            "[LightGBM] [Info] Start training from score -1.488549\n",
            "[LightGBM] [Info] Start training from score -4.082071\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:23:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114726 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 101997\n",
            "[LightGBM] [Info] Number of data points in the train set: 18585, number of used features: 400\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:25:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 55476\n",
            "[LightGBM] [Info] Number of data points in the train set: 414, number of used features: 400\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTEENN or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The EditedNearestNeighbours or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:26:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134205 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 102000\n",
            "[LightGBM] [Info] Number of data points in the train set: 12428, number of used features: 400\n",
            "[LightGBM] [Info] Start training from score -3.423820\n",
            "[LightGBM] [Info] Start training from score -0.757278\n",
            "[LightGBM] [Info] Start training from score -0.696209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ],
      "source": [
        "for res_name, resampler in resampling_methods.items():\n",
        "    if resampler:\n",
        "        X_resampled, y_resampled = resampler.fit_resample(X_train, y_train)\n",
        "    else:\n",
        "        X_resampled, y_resampled = X_train, y_train\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        y_pred = model.predict(X_test)\n",
        "        results.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Resampling\": res_name,\n",
        "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"Precision\": precision_score(y_test, y_pred, average='macro'),\n",
        "            \"Recall\": recall_score(y_test, y_pred, average='macro'),\n",
        "            \"F1-Score\": f1_score(y_test, y_pred, average='macro'),\n",
        "        })\n",
        "\n",
        "    # ANN\n",
        "    ann_model = build_ann(X_resampled.shape[1])\n",
        "    ann_model.fit(X_resampled, y_resampled, epochs=10, batch_size=32, verbose=0)\n",
        "    y_pred_ann = np.argmax(ann_model.predict(X_test), axis=1)\n",
        "    results.append({\n",
        "        \"Model\": \"ANN\",\n",
        "        \"Resampling\": res_name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred_ann),\n",
        "        \"Precision\": precision_score(y_test, y_pred_ann, average='macro'),\n",
        "        \"Recall\": recall_score(y_test, y_pred_ann, average='macro'),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred_ann, average='macro'),\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2KE4EgUl4ig",
        "outputId": "44267cb5-6a8e-481c-fe0e-5dc8f820850a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Model     Resampling  Accuracy  Precision    Recall  F1-Score\n",
            "0   Random Forest       Original  0.751100   0.453180  0.344538  0.311074\n",
            "1         XGBoost       Original  0.769682   0.481268  0.386095  0.385376\n",
            "2        LightGBM       Original  0.767237   0.476826  0.380384  0.376482\n",
            "3             ANN       Original  0.774083   0.462608  0.434258  0.441731\n",
            "4   Random Forest   Oversampling  0.753545   0.492702  0.346091  0.312985\n",
            "5         XGBoost   Oversampling  0.768215   0.462489  0.401148  0.406536\n",
            "6        LightGBM   Oversampling  0.771149   0.459967  0.429252  0.436811\n",
            "7             ANN   Oversampling  0.666504   0.442940  0.483660  0.443997\n",
            "8   Random Forest  Undersampling  0.468949   0.372720  0.415507  0.328953\n",
            "9         XGBoost  Undersampling  0.450856   0.384170  0.414821  0.328603\n",
            "10       LightGBM  Undersampling  0.451834   0.388504  0.446622  0.331269\n",
            "11            ANN  Undersampling  0.411247   0.401675  0.487946  0.292155\n",
            "12  Random Forest       Combined  0.245966   0.391486  0.335709  0.135521\n",
            "13        XGBoost       Combined  0.290954   0.409070  0.382074  0.211923\n",
            "14       LightGBM       Combined  0.292421   0.425686  0.395801  0.226842\n",
            "15            ANN       Combined  0.311980   0.409409  0.435572  0.235728\n"
          ]
        }
      ],
      "source": [
        "# Results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nTBfqagl7_D",
        "outputId": "e62539c6-7724-4a8c-f378-6f446116eeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTEENN or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The EditedNearestNeighbours or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [17:28:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 102000\n",
            "[LightGBM] [Info] Number of data points in the train set: 12428, number of used features: 400\n",
            "[LightGBM] [Info] Start training from score -3.423820\n",
            "[LightGBM] [Info] Start training from score -0.757278\n",
            "[LightGBM] [Info] Start training from score -0.696209\n",
            "\n",
            "Dengeleme Yöntemleri ile Karşılaştırma:\n",
            "           Model Sampling Type  Accuracy  Precision    Recall  F1-Score\n",
            "0  Random Forest      SMOTEENN  0.245966   0.754695  0.245966  0.106624\n",
            "1        XGBoost      SMOTEENN  0.290954   0.731104  0.290954  0.206200\n",
            "2       LightGBM      SMOTEENN  0.292421   0.731347  0.292421  0.206263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# SMOTEENN uygulaması\n",
        "smote_enn = SMOTEENN(random_state=42)\n",
        "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Dengeleme sonrası performans sonuçlarını tutmak için bir liste\n",
        "sampling_results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Modeli yeniden eğit (SMOTEENN ile dengelenmiş veriyle)\n",
        "    model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # Tahmin yap\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Performans metriklerini hesapla\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Sonuçları kaydet\n",
        "    sampling_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Sampling Type\": \"SMOTEENN\",\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1\n",
        "    })\n",
        "\n",
        "# Sonuçları bir DataFrame'e çevir\n",
        "sampling_df = pd.DataFrame(sampling_results)\n",
        "\n",
        "# Tabloyu yazdır\n",
        "print(\"\\nDengeleme Yöntemleri ile Karşılaştırma:\")\n",
        "print(sampling_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HD0iQYSl-YC",
        "outputId": "35e5a6b2-d5c2-4a18-f098-43d3fda3984d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance results saved to: /content/drive/My Drive/DATASET/performance_results.csv\n",
            "Sampling comparison saved to: /content/drive/My Drive/DATASET/sampling_comparison.csv\n"
          ]
        }
      ],
      "source": [
        "# Define the paths in your Google Drive\n",
        "performance_results_path = '/content/drive/My Drive/DATASET/performance_results.csv'\n",
        "sampling_comparison_path = '/content/drive/My Drive/DATASET/sampling_comparison.csv'\n",
        "\n",
        "# Save the DataFrames to the specified paths\n",
        "results_df.to_csv(performance_results_path, index=False)\n",
        "sampling_df.to_csv(sampling_comparison_path, index=False)\n",
        "\n",
        "print(f\"Performance results saved to: {performance_results_path}\")\n",
        "print(f\"Sampling comparison saved to: {sampling_comparison_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}